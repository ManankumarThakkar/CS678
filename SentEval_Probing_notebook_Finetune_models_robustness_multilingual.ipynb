{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "221EpIl82ACD"
      },
      "source": [
        "# @title Installing Transformers\n",
        "from IPython.display import clear_output\n",
        "!git clone https://github.com/facebookresearch/SentEval\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "clear_output()\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/cs678project/\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "8Qq5nj5WchlY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !export LC_ALL=C.UTF-8\n",
        "!ls /content/drive/MyDrive/cs678project/Fine-Tuned-Models/"
      ],
      "metadata": {
        "id": "aHWnj-GwWEtW",
        "outputId": "51cd9ab1-ceba-4a84-ed62-514df041b121",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cola-1k-123    cola-full-42   mnli-full-42    qqp-2.5k-1234  sst2-2.5k-1234\n",
            "cola-1k-42     mnli-1k-123    mrpc-1k-42      qqp-7k-123     sst2-2.5k-42\n",
            "cola-2.5k-123  mnli-1k-42     mrpc-2.5k-42    qqp-7k-1234    sst2-7k-123\n",
            "cola-2.5k-42   mnli-2.5k-123  mrpc-full-1234  qqp-full-42    sst2-7k-1234\n",
            "cola-7k-123    mnli-2.5k-42   qqp-1k-123      sst2-1k-1234   sst2-7k-42\n",
            "cola-7k-42     mnli-7k-123    qqp-1k-1234     sst2-1k-42     sst-full-42\n",
            "cola-full-123  mnli-7k-42     qqp-2.5k-123    sst2-2.5k-123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers checklist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBXxiPmDJn2u",
        "outputId": "670cef74-0f51-45e1-ec4e-8fe692787be0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: checklist in /usr/local/lib/python3.10/dist-packages (0.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: spacy>=2.2 in /usr/local/lib/python3.10/dist-packages (from checklist) (3.3.2)\n",
            "Requirement already satisfied: munch>=2.5 in /usr/local/lib/python3.10/dist-packages (from checklist) (2.5.0)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from checklist) (0.3.6)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.10/dist-packages (from checklist) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.10/dist-packages (from checklist) (7.7.1)\n",
            "Requirement already satisfied: patternfork-nosql in /usr/local/lib/python3.10/dist-packages (from checklist) (3.6)\n",
            "Requirement already satisfied: iso-639 in /usr/local/lib/python3.10/dist-packages (from checklist) (0.4.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (3.0.7)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.4.8)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (5.4.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.5.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch>=2.5->checklist) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.7.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (0.18.3)\n",
            "Requirement already satisfied: backports.csv in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (1.0.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (4.9.2)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (6.0.10)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (20221105)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (3.8.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (0.8.11)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (18.8.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=2.2->checklist) (8.1.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (5.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (5.8.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (0.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->patternfork-nosql->checklist) (2.4.1)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (9.0.0)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (3.1.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (9.1.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (3.0.post1)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (4.1.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser->patternfork-nosql->checklist) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.2->checklist) (2.1.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->patternfork-nosql->checklist) (1.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->patternfork-nosql->checklist) (40.0.2)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter>=1.0->checklist) (2.3.1)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.10/dist-packages (from cheroot>=8.2.1->cherrypy->patternfork-nosql->checklist) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (1.15.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0->checklist) (3.3.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (4.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.10/dist-packages (from portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (5.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.10/dist-packages (from jaraco.collections->cherrypy->patternfork-nosql->checklist) (3.11.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (2.21)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (0.19.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2022.7.1)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (4.3.0)\n",
            "Requirement already satisfied: autocommand in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (2.2.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJb93wOvLHAX",
        "outputId": "90fd114c-e0b3-4bf8-ad8b-e930d78bab5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqxC1_f66w3h"
      },
      "source": [
        "# @title Importing Requirements\n",
        "\n",
        "from transformers import (\n",
        "    BertConfig,\n",
        "    BertTokenizer,\n",
        "    TFBertModel,\n",
        "    BertModel,\n",
        "    glue_processors,\n",
        "    glue_convert_examples_to_features,\n",
        "    set_seed\n",
        ")\n",
        "from transformers.optimization_tf import create_optimizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "import numpy as np\n",
        "import copy \n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from checklist.editor import Editor\n",
        "from checklist.perturb import Perturb\n",
        "from checklist.test_suite import TestSuite\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPzzfc3W_KN"
      },
      "source": [
        "# @title Hyperparameters\n",
        "BATCH_SIZE =  64# @param {type:\"integer\"}\n",
        "EPOCHS =  10#@param {type:\"integer\"}\n",
        "MAX_LENGTH =   64#@param {type:\"integer\"}\n",
        "\n",
        "TASK = \"mnli\" #@param [\"cola\", \"sst\", \"mrpc\", \"sts\", \"qqp\", \"mnli\", \"qnli\", \"rte\"]\n",
        "\n",
        "MODEL_SIZE = \"full\"#@param [\"full\", \"7k\", \"2.5k\", \"1k\"]\n",
        "PROBE = \"BigramShift\" #@param ['Length','BigramShift', 'TopConst', 'Tense','SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n",
        "MODEL_SEED = \"42\" #@param [42, 123, 1234]\n",
        "PROBE_SEED = \"60\" #@param [40, 50, 60]\n",
        "num_labels = 2\n",
        "\n",
        "if PROBE == \"TopConst\":\n",
        "  num_labels = 20\n",
        "elif PROBE == 'Length':\n",
        "    num_labels = 6\n",
        "\n",
        "LEARNING_RATE =  3e-4 #@param {type:\"number\"}\n",
        "WARMUP_RATIO =   0.1 #@param {type:\"number\"}\n",
        "LAYER = \"12\" #@param [1,2,3,4, 5,6, 7,8, 9,10, 11, 12] \n",
        "LAYER = int(LAYER)\n",
        "\n",
        "#####YOU CAN REPLACE THIS LINE WITH YOUR SAVED MODEL'S PATH####\n",
        "SAVED_MODELS_DIR = f\"{DRIVE_PATH}/Fine-Tuned-Models/\" + TASK + '-' + MODEL_SIZE + '-' + str(MODEL_SEED)\n",
        "\n",
        "\n",
        "DATA_NAME = \"\"\n",
        "if PROBE == \"Length\":\n",
        "  DATA_NAME = \"sentence_length.txt\"\n",
        "elif PROBE == \"BigramShift\":\n",
        "  DATA_NAME = \"bigram_shift.txt\"\n",
        "elif PROBE == \"TopConst\":\n",
        "  DATA_NAME = \"top_constituents.txt\"\n",
        "elif PROBE == \"Tense\":\n",
        "  DATA_NAME = \"past_present.txt\"\n",
        "elif PROBE == \"SubjNumber\":\n",
        "  DATA_NAME = \"subj_number.txt\"\n",
        "elif PROBE == \"ObjNumber\":\n",
        "  DATA_NAME = \"obj_number.txt\"\n",
        "elif PROBE == \"OddManOut\":\n",
        "  DATA_NAME = \"odd_man_out.txt\"\n",
        "elif PROBE == \"CoordinationInversion\":\n",
        "  DATA_NAME = \"coordination_inversion.txt\"\n",
        "\n",
        "set_seed(int(PROBE_SEED))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEOcoyADE64P",
        "outputId": "d6420cb0-3b19-4739-e808-8a2a9b23f4cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/SentEval/data/probing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puAMWtwoaWQn",
        "outputId": "d77a405b-56f4-4833-dc62-45b9cd68d970"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram_shift.txt\t    past_present.txt\t top_constituents.txt\n",
            "coordination_inversion.txt  README.md\t\t tree_depth.txt\n",
            "obj_number.txt\t\t    sentence_length.txt  word_content.txt\n",
            "odd_man_out.txt\t\t    subj_number.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ql0uu6kPoH"
      },
      "source": [
        "with open(\"/content/SentEval/data/probing/\" + DATA_NAME, \"r\", encoding=\"utf-8\") as file_object:\n",
        "    split, label, text = [], [], []\n",
        "    for line in file_object:\n",
        "        tmp = line.strip().split('\\t')\n",
        "        split.append(tmp[0])\n",
        "        label.append(tmp[1])\n",
        "        text.append(tmp[2])\n",
        "\n",
        "df = pd.DataFrame(list(zip(split, label, text)), columns=[\"split\", \"label\", \"text\"])\n",
        "\n",
        "if PROBE != 'Length':\n",
        "    df[\"label\"] = df[\"label\"].factorize()[0]\n",
        "\n",
        "df_train = df[df[\"split\"] == \"tr\"]\n",
        "df_val = df[df[\"split\"] == \"va\"]\n",
        "df_test = df[df[\"split\"] == \"te\"]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESIaCJJjFkTI",
        "outputId": "09fbdb60-a945-4f64-e0cb-9d007a4ad205"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['split', 'label', 'text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import googletrans\n",
        "print(googletrans.LANGUAGES)\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "def batch_translate(texts, src_language, dest_language):\n",
        "    translator = Translator()\n",
        "    translations = []\n",
        "    for text in texts:\n",
        "        translation = translator.translate(text, src=src_language, dest=dest_language)\n",
        "        translations.append(translation.text)\n",
        "    return translations\n",
        "\n",
        "from pprint import pprint\n",
        "src_language = 'en'\n",
        "dest_language = 'fr'\n",
        "batch_size = 100\n",
        "\n",
        "# # create an empty column in the DataFrame to store the translations\n",
        "df['translation'] = ''\n",
        "\n",
        "# # loop over the DataFrame in batches and translate the texts\n",
        "for i in tqdm(range(0, len(df[:200]), batch_size)):\n",
        "    # print(i)\n",
        "    batch = df.iloc[i:i+batch_size]['text'].tolist()\n",
        "    batch_translations = batch_translate(batch,src_language, dest_language)\n",
        "    df.loc[i:i+batch_size-1, 'translation'] = batch_translations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-o2F5XidVfZ",
        "outputId": "1fcf4a49-ae31-49f3-db07-209386c877ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:16<00:00,  8.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfx = df[[\"label\", \"translation\"]].copy()\n",
        "print(df.columns)\n",
        "df.columns\n",
        "\n",
        "\n",
        "dfx.rename(columns={\"translation\":\"text\"}, inplace=True)"
      ],
      "metadata": {
        "id": "fgBhGq2qIWXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7216a1a3-b931-440a-d71d-0cc5f5a4ff04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['split', 'label', 'text', 'translation'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(columns=[\"translation\"], inplace =True)"
      ],
      "metadata": {
        "id": "GqfSBc97KsRA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTAmWbYJ580Y"
      },
      "source": [
        "# @title Probing Model\n",
        "\n",
        "class ProbeModel(tf.keras.Model):\n",
        "  def __init__(self, bert_model, num_labels, layer, *inputs, **kwargs):\n",
        "    super(ProbeModel, self).__init__(name=\"ProbeModel\")\n",
        "    self.bert = bert_model\n",
        "    self.bert.trainable = False\n",
        "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "    self.layer = layer\n",
        "    self.classifier = tf.keras.layers.Dense(\n",
        "                      num_labels,\n",
        "                      kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
        "                      name=\"classifier\")\n",
        "    \n",
        "  \n",
        "  def call(self, inputs, **kwargs):\n",
        "\n",
        "    outputs = self.bert(inputs, **kwargs)\n",
        "    pooled_out = outputs[2][self.layer]\n",
        "    pooled_out = pooled_out[:,0,:]\n",
        "    \n",
        "    droped_out = self.dropout(pooled_out, training=kwargs.get(\"training\", False))\n",
        "    output = self.classifier(droped_out)\n",
        "    return output"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSRtIriB9SIP"
      },
      "source": [
        "# @title Tokenizing Dataset\n",
        "def tokenization(dataframe, tokenizer, max_length):\n",
        "    input_ids, attention_mask, token_type_ids, labels = [], [], [], []\n",
        "    for _ , row in dataframe.iterrows():\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            row[\"text\"],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids.append(inputs[\"input_ids\"])\n",
        "        attention_mask.append(inputs[\"attention_mask\"])\n",
        "        token_type_ids.append(inputs[\"token_type_ids\"])\n",
        "        labels.append(row[\"label\"])\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_mask), np.array(token_type_ids), np.array(labels)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uy4xSLaeMpR",
        "outputId": "fc0ee1ab-632d-4f81-e19d-70791e143fd1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pd-Mz7IMYEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c570dc45-cba1-49b7-d3dc-17fe419ecac0"
      },
      "source": [
        "\n",
        "# @title Loading the Model\n",
        "\n",
        "config = BertConfig.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "config.output_hidden_states = True\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased', config=config)\n",
        "bert_model.output_hidden_states = True"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Eig2YZbxORla",
        "outputId": "3f55a8f4-93ba-4776-87f8-3dc2756d0240"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        label                                               text\n",
              "0           0  Une semaine, elle était avec l'homme, juste un...\n",
              "1           0  Il a versé son Dieu à Heart, et après quelques...\n",
              "2           0  Nous ne pouvons pas lui mettre sur les lieux p...\n",
              "3           1      Je détestais même entendre ce nom maintenant.\n",
              "4           0                                    C'est mon Noël.\n",
              "...       ...                                                ...\n",
              "119995      1                                                   \n",
              "119996      1                                                   \n",
              "119997      1                                                   \n",
              "119998      1                                                   \n",
              "119999      1                                                   \n",
              "\n",
              "[120000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e033ce78-19d5-44a5-8585-15585e8b33af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Une semaine, elle était avec l'homme, juste un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Il a versé son Dieu à Heart, et après quelques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous ne pouvons pas lui mettre sur les lieux p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Je détestais même entendre ce nom maintenant.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>C'est mon Noël.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119995</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119996</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119997</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e033ce78-19d5-44a5-8585-15585e8b33af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e033ce78-19d5-44a5-8585-15585e8b33af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e033ce78-19d5-44a5-8585-15585e8b33af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV3izjIm4DNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b798776c-b832-4e13-e2c7-984379b813ba"
      },
      "source": [
        "train_input_ids, train_attention_mask, train_token_type_ids, train_labels = tokenization(df_train, tokenizer, MAX_LENGTH)\n",
        "val_input_ids, val_attention_mask, val_token_type_ids, val_labels = tokenization(df_val, tokenizer, MAX_LENGTH)\n",
        "test_input_ids, test_attention_mask, test_token_type_ids, test_labels = tokenization(df_test, tokenizer, MAX_LENGTH)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_test_input_ids, french_test_attention_mask, french_test_token_type_ids, french_test_labels = tokenization(dfx[:200], tokenizer, MAX_LENGTH)"
      ],
      "metadata": {
        "id": "nPx2LP37Oa5O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# @title Preparing Probing Model\n",
        "probe_input = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"probe_input\")\n",
        "probe_mask = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"probe_mask\")\n",
        "\n",
        "probe_output = bert_model(probe_input, attention_mask=probe_mask, token_type_ids=None)[2][LAYER]\n",
        "probe_output = probe_output[:, 0, :]\n",
        "probe_output = tf.keras.layers.Dense(num_labels, activation='softmax')(probe_output)\n",
        "\n",
        "probe_model = tf.keras.Model(inputs=[probe_input, probe_mask], outputs=probe_output)\n",
        "probe_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq1VKEZKiP5h",
        "outputId": "4c7e6b1a-6a12-487b-8985-1969c5c35fad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " probe_input (InputLayer)       [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " probe_mask (InputLayer)        [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  177853440   ['probe_input[0][0]',            \n",
            "                                thPoolingAndCrossAt               'probe_mask[0][0]']             \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 64,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=(                                               \n",
            "                                (None, 64, 768),                                                  \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768),                                                 \n",
            "                                 (None, 64, 768)),                                                \n",
            "                                 attentions=None, c                                               \n",
            "                                ross_attentions=Non                                               \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][12]']         \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            1538        ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,854,978\n",
            "Trainable params: 177,854,978\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yebPoFtH_GKT"
      },
      "source": [
        "# # %%\n",
        "# # @title Compiling Probing Model\n",
        "optimizer, _ = create_optimizer(init_lr=LEARNING_RATE, num_train_steps=EPOCHS * (len(train_labels) // BATCH_SIZE), num_warmup_steps=int(WARMUP_RATIO * (EPOCHS * (len(train_labels) // BATCH_SIZE))))\n",
        "probe_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D49nsl1JL6Rz"
      },
      "source": [
        "# @title Callback\n",
        "class ModelCheckpoint(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, monitor, save_path):\n",
        "    super(ModelCheckpoint, self).__init__()\n",
        "    self.monitor = monitor\n",
        "    self.save_path = save_path\n",
        "    self.bestScore = -np.Inf\n",
        "    self.bestLoss = np.Inf\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    score = logs.get(self.monitor)\n",
        "    loss = logs.get(\"val_loss\")\n",
        "    if score > self.bestScore or (score == self.bestScore and loss < self.bestLoss):\n",
        "      path = os.path.join(TASK, str(epoch+1))\n",
        "      os.makedirs(path)\n",
        "      self.model.save_weights(path+'/best_weights.h5')\n",
        "      self.bestScore = score\n",
        "      self.bestLoss = loss\n",
        "      print(\"\\nModel saved as the best model\")\n",
        "\n",
        "monitor = \"val_accuracy\"\n",
        "checkpoint = ModelCheckpoint(monitor, SAVED_MODELS_DIR)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ahIUftw-zwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79098ac-05a3-4c4c-c369-fb0428669138"
      },
      "source": [
        "# %%\n",
        "# @title Training Probing Model\n",
        "probe_history = probe_model.fit(\n",
        "    x=[train_input_ids, train_attention_mask],\n",
        "    y=train_labels,\n",
        "    validation_data=([val_input_ids, val_attention_mask], val_labels),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint]  # Add the custom callback here\n",
        ")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8528\n",
            "Model saved as the best model\n",
            "1563/1563 [==============================] - 226s 116ms/step - loss: 0.3330 - accuracy: 0.8528 - val_loss: 0.7206 - val_accuracy: 0.5925\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 154s 99ms/step - loss: 0.6956 - accuracy: 0.5109 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 153s 98ms/step - loss: 0.6963 - accuracy: 0.4979 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6949 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6945 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6940 - accuracy: 0.5013 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 151s 97ms/step - loss: 0.6939 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6936 - accuracy: 0.5002 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6934 - accuracy: 0.5007 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 152s 97ms/step - loss: 0.6933 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhLSjbtFjzGb"
      },
      "source": [
        "# @title Retrieving the best model\n",
        "import os \n",
        "list_of_dirs = os.listdir('/content/' + TASK)\n",
        " \n",
        "\n",
        "final_list = list(map(int, list_of_dirs))\n",
        "best_model = max(final_list)\n",
        "\n",
        "model_path =\"/content/\"+ TASK + '/' + str(best_model) + '/best_weights.h5'\n",
        "probe_model.load_weights(model_path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOeujsE5ci4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864be2bd-3a8c-416c-b807-5ee75d90b9ff"
      },
      "source": [
        "# %%\n",
        "# @title Evaluating Probing Model\n",
        "evaluation = probe_model.evaluate(x=[test_input_ids, test_attention_mask], y=test_labels, batch_size=BATCH_SIZE, verbose=1)\n",
        "print(\"Test Loss: \", evaluation[0])\n",
        "print(\"Test Accuracy: \", evaluation[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 6s 39ms/step - loss: 0.7278 - accuracy: 0.5865\n",
            "Test Loss:  0.7277625799179077\n",
            "Test Accuracy:  0.5864999890327454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluating Probing Model with french\n",
        "evaluation = probe_model.evaluate(x=[french_test_input_ids, french_test_attention_mask], y=french_test_labels, batch_size=BATCH_SIZE, verbose=1)\n",
        "print(\"Test Loss: \", evaluation[0])\n",
        "print(\"Test Accuracy: \", evaluation[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEimr2vjLOSn",
        "outputId": "eaf5a5ee-16a2-474b-f1be-ca950b5f47e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 36ms/step - loss: 0.8632 - accuracy: 0.5100\n",
            "Test Loss:  0.8631762862205505\n",
            "Test Accuracy:  0.5099999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prediction function that takes a list of texts and returns a list of predictions\n",
        "def predict(texts):\n",
        "    input_ids, attention_mask, _, _ = tokenization(pd.DataFrame({'  ': texts}), tokenizer, MAX_LENGTH)\n",
        "    predictions = probe_model.predict([input_ids, attention_mask])\n",
        "    # Convert predictions to class labels if required\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "N3qY7Dv379u3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import checklist\n",
        "from checklist.editor import Editor\n",
        "from checklist.perturb import Perturb\n",
        "from checklist.test_types import MFT, INV, DIR\n",
        "from checklist.test_suite import TestSuite\n",
        "from checklist.expect import Expect"
      ],
      "metadata": {
        "id": "65iQ9JXWQsVl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import checklist\n",
        "import spacy\n",
        "import itertools\n",
        "\n",
        "import checklist.editor\n",
        "import checklist.text_generation\n",
        "from checklist.test_types import MFT, INV, DIR\n",
        "from checklist.expect import Expect\n",
        "from checklist.test_suite import TestSuite\n",
        "import numpy as np\n",
        "import spacy\n",
        "from checklist.perturb import Perturb"
      ],
      "metadata": {
        "id": "E2jHbFRxeYnm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from checklist.pred_wrapper import PredictorWrapper"
      ],
      "metadata": {
        "id": "JTuvA4TYe-NS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING = 1\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ],
      "metadata": {
        "id": "lT2SHinvkw5c"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}